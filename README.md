# PUMA

Puma aims to be a lightweight, high-performance inference engine for heterogeneous devices. *Currently under active development.*

## Supported Backends

Use [llama.cpp](https://github.com/ggerganov/llama.cpp) as the default backend for quick prototyping, will implement our own backend in the future.
